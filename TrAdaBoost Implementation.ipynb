{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom glob import glob\nimport seaborn as sns\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC \nfrom sklearn.naive_bayes import GaussianNB \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import neighbors\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import confusion_matrix \nbase_skin_dir = os.path.join('..', 'input')","execution_count":88,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}\n\nlesion_type_dict = {\n    'nv': 'Melanocytic nevi',\n    'mel': 'melanoma ',   #this is an error in the other scripts\n    'bkl': 'Benign keratosis-like lesions ',\n    'bcc': 'Basal cell carcinoma',\n    'akiec': 'Actinic keratoses',\n    'vasc': 'Vascular lesions',\n    'df': 'Dermatofibroma'\n}","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tile_df = pd.read_csv(os.path.join(base_skin_dir, 'skin-cancer-mnist-ham10000/HAM10000_metadata.csv'))\ntile_df['path'] = tile_df['image_id'].map(imageid_path_dict.get)\ntile_df['cell_type'] = tile_df['dx'].map(lesion_type_dict.get) \ntile_df['cell_type_idx'] = pd.Categorical(tile_df['cell_type']).codes\ntile_df.sample(3)\ntile_df.describe(exclude=[np.number])","execution_count":52,"outputs":[{"output_type":"execute_result","execution_count":52,"data":{"text/plain":"          lesion_id      image_id     dx dx_type    sex localization path  \\\ncount         10015         10015  10015   10015  10015        10015    0   \nunique         7470         10015      7       4      3           15    0   \ntop     HAM_0003789  ISIC_0031288     nv   histo   male         back  NaN   \nfreq              6             1   6705    5340   5406         2192  NaN   \n\n               cell_type  \ncount              10015  \nunique                 7  \ntop     Melanocytic nevi  \nfreq                6705  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lesion_id</th>\n      <th>image_id</th>\n      <th>dx</th>\n      <th>dx_type</th>\n      <th>sex</th>\n      <th>localization</th>\n      <th>path</th>\n      <th>cell_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>count</td>\n      <td>10015</td>\n      <td>10015</td>\n      <td>10015</td>\n      <td>10015</td>\n      <td>10015</td>\n      <td>10015</td>\n      <td>0</td>\n      <td>10015</td>\n    </tr>\n    <tr>\n      <td>unique</td>\n      <td>7470</td>\n      <td>10015</td>\n      <td>7</td>\n      <td>4</td>\n      <td>3</td>\n      <td>15</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <td>top</td>\n      <td>HAM_0003789</td>\n      <td>ISIC_0031288</td>\n      <td>nv</td>\n      <td>histo</td>\n      <td>male</td>\n      <td>back</td>\n      <td>NaN</td>\n      <td>Melanocytic nevi</td>\n    </tr>\n    <tr>\n      <td>freq</td>\n      <td>6</td>\n      <td>1</td>\n      <td>6705</td>\n      <td>5340</td>\n      <td>5406</td>\n      <td>2192</td>\n      <td>NaN</td>\n      <td>6705</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tile_df.isnull().sum()","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"lesion_id            0\nimage_id             0\ndx                   0\ndx_type              0\nage                 57\nsex                  0\nlocalization         0\npath             10015\ncell_type            0\ncell_type_idx        0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tile_df['age'].fillna((tile_df['age'].mean()), inplace=True)","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tile_df.isnull().sum()","execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"lesion_id            0\nimage_id             0\ndx                   0\ndx_type              0\nage                  0\nsex                  0\nlocalization         0\npath             10015\ncell_type            0\ncell_type_idx        0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"images=pd.read_csv('../input/skin-cancer-mnist-ham10000/hmnist_28_28_RGB.csv')","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check  image label equals tiledf celltype\n(images.label==tile_df.cell_type_idx).mean()","execution_count":57,"outputs":[{"output_type":"execute_result","execution_count":57,"data":{"text/plain":"1.0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nEncoder_X = LabelEncoder() \nfor col in tile_df.columns:\n    if tile_df.dtypes[col]=='object':\n        tile_df[col]=col+'_'+tile_df[col].map(str)\n        tile_df[col] = Encoder_X.fit_transform(tile_df[col])\nEncoder_y=LabelEncoder()\n#tile_df","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tile_df[['dx','dx_type','age','sex','localization','cell_type']].head()","execution_count":59,"outputs":[{"output_type":"execute_result","execution_count":59,"data":{"text/plain":"   dx  dx_type   age  sex  localization  cell_type\n0   2        3  80.0    1            11          2\n1   2        3  80.0    1            11          2\n2   2        3  80.0    1            11          2\n3   2        3  80.0    1            11          2\n4   2        3  75.0    1             4          2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dx</th>\n      <th>dx_type</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>localization</th>\n      <th>cell_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>80.0</td>\n      <td>1</td>\n      <td>11</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>80.0</td>\n      <td>1</td>\n      <td>11</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>80.0</td>\n      <td>1</td>\n      <td>11</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>80.0</td>\n      <td>1</td>\n      <td>11</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>75.0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"images=images.reset_index()\nimages=(images.T.append(tile_df[['dx_type','age','sex','localization']].T)).T\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(images.drop(['label'],axis=1),images['label'], test_size=0.2, random_state=42)","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.model_selection import cross_val_score","execution_count":97,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TrAdaboostClassifier:\n    def __init__(self, base_classifier=DecisionTreeClassifier(), N=10):\n        self.base_classifier = base_classifier\n        self.N = N\n        self.beta_all = np.zeros([1, self.N])\n        self.classifiers = []\n\n    def fitdtree(self, x_source, x_target, y_source, y_target):\n        dtree_model = DecisionTreeClassifier(max_depth = 2).fit(X_train, y_train) \n        dtree_predictions = dtree_model.predict(X_test) \n        accuracy = dtree_model.score(X_test, y_test) \n        print('Using Decision Tree as the base Learner : ')\n        print('Accuracy:')\n        print(accuracy)\n        scores = cross_val_score(dtree_model, X_test, y_test, cv=10)\n        print('Cross-Validation:')\n        print(scores)\n        #cm=confusion_matrix(y_test,dtree_predictions) \n        #print('Confusion Matrix when Decision Tree is the base Learner : ')\n        #print(cm)\n        f1=f1_score(y_test, dtree_predictions, average='weighted')\n        print('f1-score: ') \n        print(f1)\n        p=precision_recall_fscore_support(y_test,dtree_predictions, average='macro')\n        print('Precision , Recall , F-score:') \n        print(p)\n        \n    def fitsvm(self, x_source, x_target, y_source, y_target):\n        svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train) \n        svm_predictions = svm_model_linear.predict(X_test) \n        accuracy = svm_model_linear.score(X_test, y_test) \n        print('Using SVM as the base Learner: ') \n        print('Accuracy:')\n        print(accuracy)\n        scores = cross_val_score(svm_model_linear, X_test, y_test, cv=10)\n        print('Cross-Validation:')\n        print(scores)\n        #cm=confusion_matrix(y_test, svm_predictions) \n        #print('Confusion Matrix when SVM is the base Learner : ')\n        #print(cm)\n        f1=f1_score(y_test, svm_predictions, average='weighted')\n        print('f1-score:') \n        print(f1)\n        p=precision_recall_fscore_support(y_test,svm_predictions, average='macro')\n        print('Precision , Recall , F-score: ') \n        print(p)\n        \n         \n        \n    def fitnaive(self, x_source, x_target, y_source, y_target):\n        gnb = GaussianNB().fit(X_train, y_train) \n        gnb_predictions = gnb.predict(X_test) \n        accuracy = gnb.score(X_test, y_test) \n        print('Using Naive Bayes as the base Learner: ')\n        print('Accuracy:')\n        print(accuracy)\n        scores = cross_val_score(gnb, X_test, y_test, cv=10)\n        print('Cross-Validation:')\n        print(scores)\n        #cm=confusion_matrix(y_test, gnb_predictions) \n        #print('Confusion Matrix when Naive Bayes is the base Learner : ')\n        #print(cm)\n        f1=f1_score(y_test, gnb_predictions, average='weighted')\n        print('f1-score : ') \n        print(f1)\n        p=precision_recall_fscore_support(y_test,gnb_predictions, average='macro')\n        print('Precision , Recall , F-score:') \n        print(p)\n        \n    def fitrf(self, x_source, x_target, y_source, y_target):\n        model = RandomForestClassifier(n_estimators=10)\n        rf=model.fit(X_train, y_train)\n        rf_predictions=rf.predict(X_test)\n        accuracy=rf.score(X_test, y_test)\n        print('Using Random Forest Classifier as the base Learner : ')\n        print('Accuracy:')\n        print(accuracy)\n        scores = cross_val_score(rf, X_test, y_test, cv=10)\n        print('Cross-Validation:')\n        print(scores)\n        #cm=confusion_matrix(y_test, rf_predictions) \n        #print('Confusion Matrix when Random Forest Classifier is the base Learner : ')\n        #print(cm)\n        f1=f1_score(y_test, rf_predictions, average='weighted')\n        print('f1-score: ') \n        print(f1)\n        p=precision_recall_fscore_support(y_test,rf_predictions, average='macro')\n        print('Precision , Recall , F-score: ') \n        print(p)\n        \n    def fitNearestNeighbours(self, x_source, x_target, y_source, y_target):\n        model = neighbors.KNeighborsClassifier()\n        nn=model.fit(X_train, y_train)\n        nn_predictions=nn.predict(X_test)\n        accuracy=nn.score(X_test, y_test)\n        print('Using K Nearest Neighbours as the base Learner : ')\n        print(accuracy)\n        scores = cross_val_score(nn, X_test, y_test, cv=10)\n        print('Cross-Validation:')\n        print(scores)\n        #cm=confusion_matrix(y_test, rf_predictions) \n        #print('Confusion Matrix when Random Forest Classifier is the base Learner : ')\n        #print(cm)\n        f1=f1_score(y_test, nn_predictions, average='weighted')\n        print('f1-score: ') \n        print(f1)\n        p=precision_recall_fscore_support(y_test,nn_predictions, average='macro')\n        print('Precision , Recall , F-score: ') \n        print(p)\n  \n    def predict(self, x_test):\n        result = np.ones([x_test.shape[0], self.N + 1])\n        predict = []\n\n        i = 0\n        for classifier in self.classifiers:\n            y_pred = classifier.predict(x_test)\n            result[:, i] = y_pred\n            i += 1\n\n        for i in range(x_test.shape[0]):\n            left = np.sum(result[i, int(np.ceil(self.N / 2)): self.N] *\n                          np.log(1 / self.beta_all[0, int(np.ceil(self.N / 2)):self.N]))\n\n            right = 0.5 * np.sum(np.log(1 / self.beta_all[0, int(np.ceil(self.N / 2)): self.N]))\n\n            if left >= right:\n                predict.append(1)\n            else:\n                predict.append(0)\n        return predict\n\n    def predict_prob(self, x_test):\n        result = np.ones([x_test.shape[0], self.N + 1])\n        predict = []\n\n        i = 0\n        for classifier in self.classifiers:\n            y_pred = classifier.predict(x_test)\n            result[:, i] = y_pred\n            i += 1\n\n        for i in range(x_test.shape[0]):\n            left = np.sum(result[i, int(np.ceil(self.N / 2)): self.N] *\n                          np.log(1 / self.beta_all[0, int(np.ceil(self.N / 2)):self.N]))\n\n            right = 0.5 * np.sum(np.log(1 / self.beta_all[0, int(np.ceil(self.N / 2)): self.N]))\n            predict.append([left, right])\n        return predict\n\n    def _calculate_weight(self, weights):\n        sum_weight = np.sum(weights)\n        return np.asarray(weights / sum_weight, order='C')\n\n    def _calculate_error_rate(self, y_target, y_predict, weight_target):\n        sum_weight = np.sum(weight_target)\n        return np.sum(weight_target[:, 0] / sum_weight * np.abs(y_target - y_predict))\n    ","execution_count":98,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr=TrAdaboostClassifier()","execution_count":99,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.fitdtree(X_train, X_test, y_train, y_test)\ntr.fitsvm(X_train, X_test, y_train, y_test)\ntr.fitnaive(X_train, X_test, y_train, y_test)\ntr.fitrf(X_train, X_test, y_train, y_test)\ntr.fitNearestNeighbours(X_train, X_test, y_train, y_test)","execution_count":100,"outputs":[{"output_type":"stream","text":"Accuracy when Decision Tree is the base Learner : \n0.9266100848726909\nf1-score : \n0.8997699963497814\nPrecision , Recall , F-score:\n(0.5134042433110542, 0.5688044469282655, 0.5346267748793733, None)\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy when SVM is base Learner : \n0.9475786320519222\n[0.91089109 0.92537313 0.92039801 0.89949749 0.91183879]\nf1-score : \n0.9479362943574741\nPrecision , Recall , F-score: \n(0.8219100238047619, 0.8389472563696339, 0.8270580958780958, None)\nAccuracy when Naive Bayes is base Learner : \n0.5771342985521717\nf1-score : \n0.6180130700362945\nPrecision , Recall , F-score:\n(0.36992632058391706, 0.5286572540515171, 0.40946705588247256, None)\nAccuracy when Random Forest Classifier is base Learner : \n0.7863205192211683\nf1-score : \n0.7595449365491649\nPrecision , Recall , F-score: \n(0.7291381746235626, 0.4143458805745654, 0.4583063060348839, None)\nAccuracy when K Nearest Neighbours is base Learner : \n0.9515726410384423\nf1-score : \n0.9495024901998802\nPrecision , Recall , F-score: \n(0.7985096427305969, 0.7552048600956925, 0.7704854426603603, None)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.predict(X_test)","execution_count":85,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:121: RuntimeWarning: divide by zero encountered in true_divide\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:123: RuntimeWarning: divide by zero encountered in true_divide\n","name":"stderr"},{"output_type":"execute_result","execution_count":85,"data":{"text/plain":"[1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n ...]"},"metadata":{}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}